{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Reddit Posts Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoteBook Contents\n",
    "- Part 1 - Extraction, Cleansing\n",
    "- Part 2 - EDA, Pre-Proccessing, and Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Extraction, Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "\n",
    "#################################\n",
    "import folium\n",
    "import glob\n",
    "import html\n",
    "import imp\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import pickle\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import random as rand\n",
    "import re\n",
    "import requests\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "import spacy\n",
    "import statsmodels.api as sm\n",
    "import streamlit as st\n",
    "import sympy as sy\n",
    "import time\n",
    "\n",
    "#######################\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from bs4 import BeautifulSoup\n",
    "from category_encoders import OneHotEncoder as OHE\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "#from ipywidgets import *\n",
    "from ipywidgets import interact\n",
    "from math import pi\n",
    "from math import sqrt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import json_normalize\n",
    "from pathlib import Path\n",
    "#from plotter import SVMPlotter\n",
    "from random import sample\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from statsmodels.stats.weightstats import CompareMeans\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#######################\n",
    "from sklearn import svm\n",
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "#from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import TweedieRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "#from sklearn.model_selection import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#api call function applied to both subreddits used for the project\n",
    "#source: \n",
    "    # 1) https://rdrr.io/github/jfeldhege/redditoR/man/get_posts.html\n",
    "    # 2) https://stackoverflow.com/questions/48572494/structuring-api-calls-in-python\n",
    "    # 4) https://medium.com/@pasdan/how-to-scrap-reddit-using-pushshift-io-via-python-a3ebcc9b83f4\n",
    "    # 3) seperate breakout playground session walking through how to utilize Pushshift API\n",
    "\n",
    "def api_call(subred,iterations,current_epoch_time):\n",
    "    pass\n",
    "    #establish empty DataFrame\n",
    "    list_df = []\n",
    "    #url for Pushshift API subreddit\n",
    "    url = 'https://api.pushshift.io/reddit/search/submission/?subreddit='\n",
    "    #pull posts before specific date/time\n",
    "    time = current_epoch_time\n",
    "    \n",
    "    #identify params for url\n",
    "    for i in range(iterations):\n",
    "        res=requests.get(\n",
    "            url, \n",
    "            params={\n",
    "                'subreddit': subred,\n",
    "                'size': 500,\n",
    "                'lang': True,\n",
    "                'before': time\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        data = res.json()\n",
    "        posts = data['data']\n",
    "        df = json_normalize(data,'data')\n",
    "        \n",
    "        #pull specific columns\n",
    "        df = df.loc[:,['title','author','selftext','subreddit','score','created_utc','id']]\n",
    "        #append DataFrame\n",
    "        list_df.append(df)\n",
    "        \n",
    "        #add wait time\n",
    "        sleeptime = np.random.randint(1, 3)\n",
    "        time.sleep(sleeptime)\n",
    "        \n",
    "        #establish current time\n",
    "        time = df['created_utc'].min()\n",
    "    \n",
    "    return pd.concat(list_df, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I switched the code cells below to raw-type cells because the api_call function takes forever to run. I exported the DataFrames as CSV files after original run"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#dfsports extraction\n",
    "\n",
    "df_sports = api_call('dfsports', 50, 1610747849)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_sports.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#add identifier column to distinguish subreddits when merged later\n",
    "\n",
    "df_sports['is_fantasyfootball'] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#pull api_call output DataFrame to csv file\n",
    "\n",
    "df_sports.to_csv('../datasets/df_sports.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#fantasyfootball extraction\n",
    "\n",
    "df_fantasy = api_call('fantasyfootball', 50, 1610747849)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_fantasy.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#add identifier column to distinguish subreddits when merged later\n",
    "\n",
    "df_fantasy['is_fantasyfootball'] = 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#pull api_call output DataFrame to csv file\n",
    "\n",
    "df_fantasy.to_csv('../datasets/df_fantasy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull back in csv files reflecting both api_call output DataFrames for the two subreddits\n",
    "\n",
    "fantasy_df = pd.read_csv('../datasets/df_fantasy.csv', keep_default_na=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>is_fantasyfootball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NFL on Twitter- Falcons hire Arthur Smith as n...</td>\n",
       "      <td>TheFFnerd</td>\n",
       "      <td></td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>4</td>\n",
       "      <td>1610747812</td>\n",
       "      <td>ky4x5u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Seahawks WR Josh Gordon's conditional reinsta...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1610746600</td>\n",
       "      <td>ky4i5o</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     author   selftext  \\\n",
       "0  NFL on Twitter- Falcons hire Arthur Smith as n...  TheFFnerd              \n",
       "1  #Seahawks WR Josh Gordon's conditional reinsta...  [deleted]  [deleted]   \n",
       "\n",
       "         subreddit  score  created_utc      id  is_fantasyfootball  \n",
       "0  fantasyfootball      4   1610747812  ky4x5u                   1  \n",
       "1  fantasyfootball      1   1610746600  ky4i5o                   1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fantasy_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_df = pd.read_csv('../datasets/df_sports.csv', keep_default_na=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>is_fantasyfootball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What does this mean?</td>\n",
       "      <td>TheRegal6</td>\n",
       "      <td>I got an email saying ‚ÄúWe just need you to wri...</td>\n",
       "      <td>dfsports</td>\n",
       "      <td>1</td>\n",
       "      <td>1610747631</td>\n",
       "      <td>ky4uur</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEST DraftKings &amp;amp; FanDuel NBA DFS Core 4 P...</td>\n",
       "      <td>dfsndonuts</td>\n",
       "      <td>Tonight‚Äôs Best [DraftKings and FanDuel NBA DF...</td>\n",
       "      <td>dfsports</td>\n",
       "      <td>2</td>\n",
       "      <td>1610743477</td>\n",
       "      <td>ky3erf</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      author  \\\n",
       "0                               What does this mean?   TheRegal6   \n",
       "1  BEST DraftKings &amp; FanDuel NBA DFS Core 4 P...  dfsndonuts   \n",
       "\n",
       "                                            selftext subreddit  score  \\\n",
       "0  I got an email saying ‚ÄúWe just need you to wri...  dfsports      1   \n",
       "1   Tonight‚Äôs Best [DraftKings and FanDuel NBA DF...  dfsports      2   \n",
       "\n",
       "   created_utc      id  is_fantasyfootball  \n",
       "0   1610747631  ky4uur                   0  \n",
       "1   1610743477  ky3erf                   0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge both subreddit outputs\n",
    "combined_df = fantasy_df.append(sports_df,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export merged DataFrame to csv file to save copy\n",
    "combined_df.to_csv('../datasets/combined_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull back in merged DataFrame\n",
    "final_df = pd.read_csv('../datasets/combined_df.csv', keep_default_na=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>is_fantasyfootball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NFL on Twitter- Falcons hire Arthur Smith as n...</td>\n",
       "      <td>TheFFnerd</td>\n",
       "      <td></td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>4</td>\n",
       "      <td>1610747812</td>\n",
       "      <td>ky4x5u</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Seahawks WR Josh Gordon's conditional reinsta...</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1610746600</td>\n",
       "      <td>ky4i5o</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     author   selftext  \\\n",
       "0  NFL on Twitter- Falcons hire Arthur Smith as n...  TheFFnerd              \n",
       "1  #Seahawks WR Josh Gordon's conditional reinsta...  [deleted]  [deleted]   \n",
       "\n",
       "         subreddit  score  created_utc      id  is_fantasyfootball  \n",
       "0  fantasyfootball      4   1610747812  ky4x5u                   1  \n",
       "1  fantasyfootball      1   1610746600  ky4i5o                   1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 0 to 99\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   title               10000 non-null  object\n",
      " 1   author              10000 non-null  object\n",
      " 2   selftext            10000 non-null  object\n",
      " 3   subreddit           10000 non-null  object\n",
      " 4   score               10000 non-null  int64 \n",
      " 5   created_utc         10000 non-null  int64 \n",
      " 6   id                  10000 non-null  object\n",
      " 7   is_fantasyfootball  10000 non-null  int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 703.1+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new DataFrame reflecting object type columns only\n",
    "objects_df = final_df.select_dtypes(['object'])\n",
    "\n",
    "#trim values in origianl DataFrame if they exist in the temp \"objects\" DataFrame\n",
    "final_df[objects_df.columns] = objects_df.apply(lambda a: a.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify any posts with empty, [deleted], or [removed] values -> replace with a NULL value\n",
    "final_df['selftext'].replace(\"[removed]\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['selftext'].replace(\"[deleted]\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['selftext'].replace(\"\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['selftext'].replace(\" \", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-19 14:27:27.740 INFO    numexpr.utils: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "#drop NULLs to remove the bad post data\n",
    "final_df = final_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop any duplicate posts if they exist\n",
    "final_df.drop_duplicates(subset='selftext', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                 0\n",
       "author                0\n",
       "selftext              0\n",
       "subreddit             0\n",
       "score                 0\n",
       "created_utc           0\n",
       "id                    0\n",
       "is_fantasyfootball    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for NULLs - removed in extraction notebook so shouldn't be any\n",
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5608 entries, 4 to 96\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   title               5608 non-null   object\n",
      " 1   author              5608 non-null   object\n",
      " 2   selftext            5608 non-null   object\n",
      " 3   subreddit           5608 non-null   object\n",
      " 4   score               5608 non-null   int64 \n",
      " 5   created_utc         5608 non-null   int64 \n",
      " 6   id                  5608 non-null   object\n",
      " 7   is_fantasyfootball  5608 non-null   int64 \n",
      "dtypes: int64(3), object(5)\n",
      "memory usage: 394.3+ KB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>is_fantasyfootball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>A song for my kicker.</td>\n",
       "      <td>Hugh_Bromont</td>\n",
       "      <td>\"Amid the chaos of that day, when all I could ...</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1609184760</td>\n",
       "      <td>klxgi2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>That's what Josh Jacob gets for trolling fanta...</td>\n",
       "      <td>stevendom1987</td>\n",
       "      <td>\"Cuhh KARMA IS A BITCH üòÇüòÇ\"\\n\\n[His Tweet](http...</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1609048373</td>\n",
       "      <td>kkyd09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Sunday Night Clinching Club! Congrats to every...</td>\n",
       "      <td>randomq17</td>\n",
       "      <td>\"On any given Sunday.\" A phrase we all know al...</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1608526938</td>\n",
       "      <td>khakct</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ProFootballDoc on CEH injury</td>\n",
       "      <td>HookFL</td>\n",
       "      <td>\"The Chiefs running back was tackled in an awk...</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1608526200</td>\n",
       "      <td>khad7k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Analyzing the Confusing Minutes of the Nuggets...</td>\n",
       "      <td>LightningNissan</td>\n",
       "      <td># Clippers\\n\\n* **IMPORTANT - We know that the...</td>\n",
       "      <td>dfsports</td>\n",
       "      <td>3</td>\n",
       "      <td>1599985557</td>\n",
       "      <td>irujet</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Kamaracaust</td>\n",
       "      <td>necisizer</td>\n",
       "      <td>~~Five~~ SIX rushing TDs today. It's utter ins...</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1608944091</td>\n",
       "      <td>kk9gdg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Derrick Henry take our energy energy thread</td>\n",
       "      <td>Duma123</td>\n",
       "      <td>‡ºº „Å§ ‚óï_‚óï ‡ºΩ„Å§ DERRICK HENRY TAKE MY ENERGY ‡ºº „Å§ ‚óï_...</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1608943967</td>\n",
       "      <td>kk9f6l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Derrick Henry take our energy thread</td>\n",
       "      <td>Duma123</td>\n",
       "      <td>‡ºº „Å§ ‚óï_‚óï ‡ºΩ„Å§ DERRICK HENRY TAKE MY ENERGY ‡ºº „Å§ ‚óï_...</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>1</td>\n",
       "      <td>1608944036</td>\n",
       "      <td>kk9fub</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>4/9 DK LOL SPREADSHEET</td>\n",
       "      <td>King-Slick</td>\n",
       "      <td>‚Ä™The best #DFS #LeagueofLegends spreadsheet. D...</td>\n",
       "      <td>dfsports</td>\n",
       "      <td>1</td>\n",
       "      <td>1586390926</td>\n",
       "      <td>fxi00f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NFL DFS - Tournament/GPP Plays, Stacks, and Da...</td>\n",
       "      <td>outdoorscat123</td>\n",
       "      <td>üí≤ üí≤üí≤ GPP Options, Game Stacks, and Dart Throws...</td>\n",
       "      <td>dfsports</td>\n",
       "      <td>1</td>\n",
       "      <td>1609088104</td>\n",
       "      <td>kl6w17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5608 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title           author  \\\n",
       "50                              A song for my kicker.     Hugh_Bromont   \n",
       "16  That's what Josh Jacob gets for trolling fanta...    stevendom1987   \n",
       "81  Sunday Night Clinching Club! Congrats to every...        randomq17   \n",
       "88                       ProFootballDoc on CEH injury           HookFL   \n",
       "18  Analyzing the Confusing Minutes of the Nuggets...  LightningNissan   \n",
       "..                                                ...              ...   \n",
       "26                                    The Kamaracaust        necisizer   \n",
       "28        Derrick Henry take our energy energy thread          Duma123   \n",
       "27               Derrick Henry take our energy thread          Duma123   \n",
       "65                             4/9 DK LOL SPREADSHEET       King-Slick   \n",
       "8   NFL DFS - Tournament/GPP Plays, Stacks, and Da...   outdoorscat123   \n",
       "\n",
       "                                             selftext        subreddit  score  \\\n",
       "50  \"Amid the chaos of that day, when all I could ...  fantasyfootball      1   \n",
       "16  \"Cuhh KARMA IS A BITCH üòÇüòÇ\"\\n\\n[His Tweet](http...  fantasyfootball      1   \n",
       "81  \"On any given Sunday.\" A phrase we all know al...  fantasyfootball      1   \n",
       "88  \"The Chiefs running back was tackled in an awk...  fantasyfootball      1   \n",
       "18  # Clippers\\n\\n* **IMPORTANT - We know that the...         dfsports      3   \n",
       "..                                                ...              ...    ...   \n",
       "26  ~~Five~~ SIX rushing TDs today. It's utter ins...  fantasyfootball      1   \n",
       "28  ‡ºº „Å§ ‚óï_‚óï ‡ºΩ„Å§ DERRICK HENRY TAKE MY ENERGY ‡ºº „Å§ ‚óï_...  fantasyfootball      1   \n",
       "27  ‡ºº „Å§ ‚óï_‚óï ‡ºΩ„Å§ DERRICK HENRY TAKE MY ENERGY ‡ºº „Å§ ‚óï_...  fantasyfootball      1   \n",
       "65  ‚Ä™The best #DFS #LeagueofLegends spreadsheet. D...         dfsports      1   \n",
       "8   üí≤ üí≤üí≤ GPP Options, Game Stacks, and Dart Throws...         dfsports      1   \n",
       "\n",
       "    created_utc      id  is_fantasyfootball  \n",
       "50   1609184760  klxgi2                   1  \n",
       "16   1609048373  kkyd09                   1  \n",
       "81   1608526938  khakct                   1  \n",
       "88   1608526200  khad7k                   1  \n",
       "18   1599985557  irujet                   0  \n",
       "..          ...     ...                 ...  \n",
       "26   1608944091  kk9gdg                   1  \n",
       "28   1608943967  kk9f6l                   1  \n",
       "27   1608944036  kk9fub                   1  \n",
       "65   1586390926  fxi00f                   0  \n",
       "8    1609088104  kl6w17                   0  \n",
       "\n",
       "[5608 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.sort_values(by=['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3912\n",
       "1    1696\n",
       "Name: is_fantasyfootball, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count how many post per subreddit are left after cleanising process\n",
    "final_df['is_fantasyfootball'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export merged DataFrame to csv file to use for modeling\n",
    "final_df.to_csv('../datasets/final_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
